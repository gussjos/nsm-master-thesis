{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Notes"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport sys\nsys.path.append(\"..\") #Adds the module to path\n#import os\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n!git clone https://github.com/gussjos/DeepTrack-2.0","execution_count":3,"outputs":[{"output_type":"stream","text":"fatal: destination path 'DeepTrack-2.0' already exists and is not an empty directory.\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function\nimport tensorflow as tf\n#physical_devices=tf.config.experimental.list_physical_devices('GPU')\n#tf.config.experimental.set_memory_growth(physical_devices[0],True)\n#tf.config.gpu.set_per_process_memory_fraction(0.75)\n#tf.config.gpu.set_per_process_memory_growth(True)\nimport numpy as np\nimport scipy.io as IO\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nimport scipy.io as IO\nimport os\nK=keras.backend\nsys.path.insert(0,'DeepTrack-2.0/')\nimport deeptrack as dt\n# Font parameters\nsz = 14\nplt.rc('font', size=sz)          # controls default text sizes\nplt.rc('axes', titlesize=sz)     # fontsize of the axes title\nplt.rc('axes', labelsize=sz)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=sz)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=sz)    # fontsize of the tick labels\nplt.rc('legend', fontsize=sz)    # legend fontsize\nplt.rc('figure', titlesize=sz)  # fontsize of the figure title","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define network and load weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Works with Tensorflow 2.2.0 and Keras 2.3.1\nfrom deeptrack.models import resnetcnn, Convolutional\nfrom deeptrack.losses import unet_features,nd_mean_absolute_error\n\nfrom keras import models, layers, optimizers, backend, activations\nimport numpy as np\nimport tensorflow as tf\n\ndef conv_step(layer,dimension):\n           layer=layers.Conv2D(dimension,kernel_size=3,activation=\"relu\",padding=\"same\")(layer)\n           return layer\n        \ndef _compile(model: models.Model, \n            *,\n            loss=\"mae\", \n            optimizer=\"adam\", \n            metrics=[],\n            **kwargs):\n    ''' Compiles a model.\n\n    Parameters\n    ----------\n    model : keras.models.Model\n        The keras model to interface.\n    loss : str or keras loss\n        The loss function of the model.\n    optimizer : str or keras optimizer\n        The optimizer of the model.\n    metrics : list, optional\n    '''\n\n    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n    return model","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Histogram"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ds = (diffs[mask>0.2]).flatten()**2*57\n# print(np.mean(ds))\n\n# #ds = ((diffs*mask*np.sum(diffs*mask))**2*57).flatten()\n# #ds = ds[ds>0.1]\n# H = plt.hist(ds,bins=30)\n# #np.sum(ds)**2*57","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plots to compare output from resnet"},{"metadata":{"trusted":true},"cell_type":"code","source":"from deeptrack.losses import nd_mean_absolute_error\nunet_path = '../input/network-weights/unet-1-dec-1415.h5'\nunet = tf.keras.models.load_model(unet_path,compile=False)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# j = 9\n# preds = resnet.predict(b)\n\n# plt.imshow(np.squeeze(b[j,...]).T)\n\n# # Label mask\n# plt.figure()\n# Lmask = L[j][...,-1]\n# plt.imshow(Lmask.T)#/np.sum(mask))\n# plt.colorbar()\n\n# # Mask\n# plt.figure()\n# mask = np.squeeze(preds[1][j,...,-1]).T\n# plt.imshow(mask)#/np.sum(mask))\n# plt.colorbar()\n\n# plt.figure()\n# diffs = np.squeeze(preds[2][j,...]).T\n# plt.imshow(diffs)\n# plt.colorbar()\n\n# print('D_label: {}'.format(L[j,0,0,0]**2*57))\n# print('D_pred: {}'.format(preds[0][j]**2*57))\n\n\n# # How diffusion is calculated from the mask\n# #np.sum(mask*diffs/np.sum(mask))**2*57\n# np.mean(mask*diffs)**2*57\n# #print(np.mean(mask*diffs)**2*57)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_predictions(resnet,b,L):\n    x = np.linspace(0,1)\n    plt.plot(x,x)\n    \n    D_true = L[:,0,0,0]\n    D_pred = resnet.predict(b)[0]\n    #print(D_pred.shape)\n    #print(D_true.shape)\n    plt.scatter(D_true,D_pred) \n    \n    #print(resnet.predict(b)[1][...,-1].shape)\n    \n    masks = resnet.predict(b)[1][...,-1]\n    \n    fig, ax = plt.subplots(1,3,figsize=(10,6))\n    \n    j = np.random.randint(batch_size)\n    cax = ax[0]\n    cax.imshow(L[...,1][j].T)\n    \n    cax = ax[1]\n    cax.imshow(np.squeeze(masks[j]).T)\n    \n    cax = ax[2]\n    plt.imshow(np.squeeze(b[j]).T)\n    plt.show()","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict on entire images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict on all available data\n\n\ndef predict_on_testdata(resnet, unet, meas_indices, Ds, iOCs, DX, print_outputs):\n    # DX: channel_length/2\n    \n    meas_i1 = meas_indices[0]\n    meas_i2 = meas_indices[1]\n\n    def reset_estimates():\n        estimates = {'D10_iOC0.0001': {'D':[], 'iOC':[]},\n                     'D10_iOC0.0002': {'D':[], 'iOC':[]},\n                     'D10_iOC0.0005': {'D':[], 'iOC':[]},\n                     'D20_iOC0.0001': {'D':[], 'iOC':[]},\n                     'D20_iOC0.0002': {'D':[], 'iOC':[]},\n                     'D20_iOC0.0005': {'D':[], 'iOC':[]},\n                     'D50_iOC0.0001': {'D':[], 'iOC':[]},\n                     'D50_iOC0.0002': {'D':[], 'iOC':[]},\n                     'D50_iOC0.0005': {'D':[], 'iOC':[]},};\n        return estimates\n\n    estimates = reset_estimates() # store data in estimates\n\n    # Choose path depending on which images to use\n    #img_path = '../input/testdata-17-dec-new/'\n    img_path = '../input/test-data-no-bgstd-7-jan/'\n    std_path = '../input/noise-std-23-dec-2/'\n\n    convert_to_real_units = 1\n    images = os.listdir(img_path)\n\n    for iOC in iOCs:\n        for D in Ds:\n            D_str = 'D' + str(D)\n            iOC_str = 'iOC' + str(iOC)\n            combination = D_str + '_' + iOC_str\n            if print_outputs:\n                print(f'Current combination: {iOC_str} & {D_str}')\n\n            # Pick out all measurements for current comb. of D, iOC\n            files = [file for file in images if iOC_str in file]\n            files = [file for file in files if D_str in file]\n            \n            for j, file in enumerate(files[meas_i1:meas_i2]):  \n                Bsm = np.load(img_path + file, allow_pickle=True)\n                \n                # Normalize\n                #Bsm /= np.max(np.max(Bsm))\n                \n                Bsm_d = Bsm.T\n                Bsm_r = Bsm_d.reshape(1,Bsm_d.shape[0],Bsm_d.shape[1],1) # reshape for input to network\n                #Bsm_r = Bsm_r[:1,11:-11,:8192+1024,:1]\n                Bsm_r = Bsm_r[:1,11:-11,256:8192+1024-256,:1]\n                \n                #std = np.load(std_path + file)\n                \n                #print('a:',np.mean(a))\n                #print('b:',np.mean(b))\n                \n                #print(Bsm_r.shape)\n                #segm = unet.predict(Bsm_r.T)\n                #segm[segm<0] = 0\n                #print(Bsm_r.shape)\n                iOC_val, mask = resnet.predict(Bsm_r.T)\n                \n                #a = std\n                iOC_val = iOC_val[0][0]#*a#*1000#*1000#*np.mean(a) #**2*57/256**2 * DX**2\n                estimates[combination]['D'].append(iOC_val)\n                #estimates[combination]['iOC'].append(iOC_val)\n                \n                if print_outputs:\n                    print(f'file {j+1}/{len(files)} done')\n                    print(f'\\t iOC_val = {\"{:.4f}\".format(iOC_val)}')\n            if print_outputs:\n                print()\n            \n    return estimates\n\n# iOCs = np.array([1,2,5])*1e-4\n# Ds = np.array([10,20,50])\n# meas_indices = [0,5]\n# print_outputs = 1\n\n\n#estimates = predict_on_testdata(resnet, unet, meas_indices, Ds, iOCs, DX, print_outputs)\n# avg_estimates = calculate_estimates(estimates, iOCs, Ds, print_outputs)\n\n# plot_test_predictions(avg_estimates)        ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save estimates\nimport pandas as pd\ndef calculate_estimates(estimates, iOCs, Ds, print_outputs):\n    np.save('estimates.npy',estimates)\n\n    A = np.load('estimates.npy',allow_pickle='TRUE').item()\n    avg_estimates = {'D10_iOC0.0001': {'D':[],   'std_D':[],  },\n                     'D10_iOC0.0002': {'D':[],   'std_D':[],  },\n                     'D10_iOC0.0005': {'D':[],   'std_D':[],  },\n                     'D20_iOC0.0001': {'D':[],   'std_D':[],  },\n                     'D20_iOC0.0002': {'D':[],   'std_D':[],  },\n                     'D20_iOC0.0005': {'D':[],   'std_D':[],  },\n                     'D50_iOC0.0001': {'D':[],   'std_D':[],  },\n                     'D50_iOC0.0002': {'D':[],   'std_D':[],  },\n                     'D50_iOC0.0005': {'D':[],   'std_D':[],  },}\n    # Average over combinations\n    nbr_segments = 1\n    for iOC in iOCs:\n        for D in Ds:\n            iOC_str = 'iOC' + str(iOC)\n            D_str = 'D' + str(D)\n            combination = D_str + '_' + iOC_str\n\n            D_vals = np.array(A[combination]['D'])\n            #print(D_vals)\n            #print(np.mean(D_vals))\n            avg_estimates[combination]['D'] = np.mean(D_vals)\n            avg_estimates[combination]['std_D'] = np.std(D_vals)\n\n    est_df = pd.DataFrame(avg_estimates)\n    if print_outputs:\n        display(est_df)\n    return avg_estimates\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract averages per simulated iOC #2\n\ndef plot_test_predictions(avg_estimates,plot_Ds, I_scaling_factor):\n    iOC_arr_D10 = []\n    iOC_arr_D20 = []\n    iOC_arr_D50 = []\n    \n    iOC_std_D10 = []\n    iOC_std_D20 = []\n    iOC_std_D50 = []\n\n    D50 = np.array(3*[50])\n    D20 = np.array(3*[20])\n    D10 = np.array(3*[10])\n\n    for j in [1,2,5]:\n        est_str = f'D10_iOC0.000{j}'\n        est = avg_estimates[est_str]\n        \n        iOC_arr_D10.append(est['D']*I_scaling_factor)\n        iOC_std_D10.append(est['std_D']*I_scaling_factor)\n\n    for j in [1,2,5]:\n        est_str = f'D20_iOC0.000{j}'\n        est = avg_estimates[est_str]\n        \n        iOC_arr_D20.append(est['D']*I_scaling_factor)\n        iOC_std_D20.append(est['std_D']*I_scaling_factor)\n\n\n    for j in [1,2,5]:\n        est_str = f'D50_iOC0.000{j}'\n        est = avg_estimates[est_str]\n        \n        iOC_arr_D50.append(est['D']*I_scaling_factor)\n        iOC_std_D50.append(est['std_D']*I_scaling_factor)\n\n\n    plt.figure(figsize=(5,5))\n\n    elw = 1.5\n    if plot_Ds[2]:\n        plt.scatter(iOC_arr_D50, D50, label='D=50', color='tab:blue')\n        plt.errorbar(iOC_arr_D50, D50, xerr = iOC_std_D50, fmt='.',\n                        capsize=5, elinewidth=elw, color = 'tab:blue')\n    if plot_Ds[1]:\n        plt.scatter(iOC_arr_D20, D20, label='D=20', color='tab:orange')\n        plt.errorbar(iOC_arr_D20, D20, xerr = iOC_std_D20, fmt='.',\n                        capsize=5, elinewidth=elw, color = 'tab:orange')\n    if plot_Ds[0]:\n        plt.scatter(iOC_arr_D10, D10, label='D=10', color='tab:green')\n        plt.errorbar(iOC_arr_D10, D10, xerr = iOC_std_D10, fmt='.',\n                        capsize=5, elinewidth=elw, color = 'tab:green')\n\n\n\n    # Plot expected D-vals\n    #plt.axvline(1e-4,linewidth = 0.65,linestyle='--',color='black')\n    #plt.axvline(2e-4,linewidth = 0.65,linestyle='--',color='black')\n    #plt.axvline(5e-4,linewidth = 0.65,linestyle='--',color='black')\n\n\n    #plt.text(np.min(D_arr_iOC5), np.mean(iOC_arr_iOC5)+h,f'{\"{:.2f}\".format(c5)}x iOC 1e-4')\n    #plt.text(np.min(D_arr_iOC5), np.mean(iOC_arr_iOC2)+h,f'{\"{:.2f}\".format(c2)}x iOC 1e-4')\n    #plt.text(np.min(D_arr_iOC5), np.mean(iOC_arr_iOC1)+h,f'iOC 1e-4')\n    \n    #plt.xlim(0,6e-4)\n    plt.ylim(0,60)\n\n    plt.xlabel('iOC (1e-4)', fontsize=14)\n    plt.ylabel(r'$D [\\mu$m$^2$/s]', fontsize=14)\n    plt.title('Mean predictions over all measurements',fontsize=14)\n    plt.legend(fontsize=12)\n    plt.show()\n","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comment: Run all above Train for plots to work in training loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"unet = None\nresnet.load_weights('../input/resnet-11-jan-int/intensities_11jan.h5')\n\nmeas_indices = [0,10]\nprint_outputs = 1\nlength = 512\nDX = length/2\nD_arr = [10,20,50]\nestimates = predict_on_testdata(resnet, unet, meas_indices, D_arr, iOCs, DX, print_outputs)\navg_estimates = calculate_estimates(estimates, iOCs, D_arr, print_outputs)\n\nplot_Ds = [1,1,1]\nI_scaling_factor = 1\nplot_test_predictions(avg_estimates,plot_Ds,I_scaling_factor) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('D10')\nprint(avg_estimates['D10_iOC0.0002']['D'] - avg_estimates['D10_iOC0.0001']['D'])\nprint(avg_estimates['D10_iOC0.0005']['D'] - avg_estimates['D10_iOC0.0001']['D'])\nprint('D20')\nprint(avg_estimates['D20_iOC0.0002']['D'] - avg_estimates['D20_iOC0.0001']['D'])\nprint(avg_estimates['D20_iOC0.0005']['D'] - avg_estimates['D20_iOC0.0001']['D'])\nprint('D50')\nprint(avg_estimates['D50_iOC0.0002']['D'] - avg_estimates['D50_iOC0.0001']['D'])\nprint(avg_estimates['D50_iOC0.0005']['D'] - avg_estimates['D50_iOC0.0001']['D'])\n\nprint(avg_estimates['D50_iOC0.0005']['D'])\nprint(avg_estimates['D50_iOC0.0002']['D'])\nprint(avg_estimates['D50_iOC0.0001']['D'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_Ds = [1,1,1]\nD_arr = np.array([10,20,50])\nI_scaling_factor = 1\nplot_test_predictions(avg_estimates,plot_Ds,I_scaling_factor) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot testdata for visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"j = 51\npath = '../input/test-data-no-bgstd-7-jan/'\n#path = '../input/testdata-17-dec-new/'\nfiles = os.listdir(path)\nfilename = files[j]\n\nfilename = '24-08-20_16-47-20_D20_iOC0.0001_M.mat.npy'\nfile = path + filename\nprint(file)\nA = np.load(file)\n\n# Plot testdata\nplt.figure(figsize=(16,2))\ni1 = 1024\nplt.imshow(A.T[:,i1:i1+1024],aspect = 'auto')\nplt.colorbar()\n\n# Plot segmentation of testdata \nN = int((150-128)/2)\nB = A[:8192,N:-N]\nB = np.reshape(B,(1,8192,128,1))\nP = np.squeeze(unet.predict(B)).T\nplt.figure(figsize=(16,2))\nplt.imshow(P[:,i1:i1+1024],aspect = 'auto')\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j = 1\nplt.imshow(b[j,...,0].T)\nplt.colorbar()\n\np = resnet.predict(b)[0][j]\n\nprint('pred:',p)\nprint('label:',L[j,0,0,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in range(0,8):\n    im = b[j,...,0]\n    A = np.std(im,axis=0)\n    A = skimage.measure.block_reduce(A,(25,), np.mean)\n    plt.plot(A)","execution_count":14,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'b' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-c39548479f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"# Define images"},{"metadata":{"trusted":true},"cell_type":"code","source":"I = 0.5\ns = 0.04\ngauss_integral = s*np.sqrt(2*np.pi)\ntrain_dx = 256\nreal_dx = 0.03\nconv_factor = train_dx*real_dx\nI/(gauss_integral*conv_factor)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"0.6493201178408736"},"metadata":{}}]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import deeptrack as dt\nfrom deeptrack.features import Feature\nimport numpy as np\nimport skimage.measure\n\n# class set_params(Feature):\n    \n#     def __init__(self, vel=0, D=0, I=0, s=0, **kwargs):\n#         super().__init__(\n#             vel=vel, D=D, I=I,s=s, **kwargs\n#         )\n\n#     def get(self, image, vel, D, I,s, **kwargs):\n#         Int = lambda : 1e-3 * (0.6)#0.4*np.random.rand())\n#         Ds = 0.1*np.sqrt(0.05+1.5*np.random.rand()) # Diffusions are defined in get_diffusion()!   lambda: 0.10*(0.05+1.5*np.random.rand())#np.sqrt((0.05 + np.random.rand()))\n#         st = lambda: 0.04 + 0.01*np.random.rand()\n#         image.append({\"D\": 10*D})\n#         image.append({\"I\": s*I*np.sqrt(2*np.pi)*256*.03*1000})\n#         image.append({\"s\": s})\n        \n#         return image\n    \nclass get_diffusion_and_intensity(Feature):\n    \n    def __init__(self, vel=0, D=0, I=0, s=0, **kwargs):\n        super().__init__(\n            vel=vel, D=D, I=I,s=s, **kwargs\n        )\n\n    def get(self, image, vel, D, I,s, **kwargs):\n        LOW = 0.01\n        HIGH = 1\n        D = (LOW + HIGH*np.random.rand())\n        image.append({\"D\":D})\n        \n        s = 0.04 + 0.01*np.random.rand()\n        image.append({\"s\":s})\n        \n        I1 = 0.001\n        I2 = 0.5\n        I_max = I1+I2\n        I = 1e-3 * (I1+I2*np.random.rand())\n        image.append({\"I_initial\":s*I*np.sqrt(2*np.pi)*256*.03*1000/I_max})\n        \n        return image\n    \nclass get_trajectory(Feature):\n\n    \n    def __init__(self, vel=0, D=0.1, I=0.1,s=0.05, **kwargs):\n        super().__init__(\n            vel=vel, D=D, I=I,s=s, **kwargs\n        )\n\n    def get(self, image, vel, D, I,s, **kwargs):\n        \n        \n        D = image.get_property(\"D\")/10\n        I = image.get_property(\"I_initial\")/1000\n        s = image.get_property(\"s\")\n        \n        length=image.shape[1]\n        times=image.shape[0]\n        x=np.linspace(-1,1,length)\n        t=np.linspace(-1,1,times)\n        X, Y=np.meshgrid(t,x)\n        G= lambda a,b,x0,s,x: a*np.exp(-(x-x0)**2/s**2)+b\n        f2=lambda a,x0,s,b,x: a*np.exp(-(x-x0)**2/s**2)+b\n        x0=0\n        x0+=np.cumsum(vel+D*np.random.randn(times))\n        v1=np.transpose(I*f2(1,x0,s,0,Y))\n        image[...,0]*=(1-v1)\n        image[...,1]+=np.transpose(f2(1,x0,0.05,0,Y))\n        #image[...,2]+=np.transpose(I*f2(1,x0,s,0,Y))\n        \n#         try:\n#             image.properties[\"D\"]+=10*D#*np.sum(np.transpose(f2(1,x0,.1,0,Y)))\n#             image.properties[\"I\"]+=s*I*np.sqrt(2*np.pi)*256*.03*1000\n#         except:\n#             image.append({\"D\":10*D,\"I\":s*I*np.sqrt(2*np.pi)*256*.03*1000})\n            \n        #imaged_sample[...,0]=v1\n        #imaged_sample.properties=self.properties\n        return image\n    \nclass gen_noise(Feature):\n    \n    \n    def __init__(self, noise_lev=0, dX=0, dA=0,biglam=0,bgnoiseCval=0,bgnoise=0,bigx0=0, **kwargs):\n        super().__init__(\n            noise_lev=noise_lev, dX=dX, dA=dA,biglam=biglam,bgnoiseCval=bgnoiseCval,bgnoise=bgnoise,bigx0=bigx0, **kwargs\n        )\n\n    def get(self, image, noise_lev, dX, dA,biglam,bgnoiseCval,bgnoise,bigx0, **kwargs):\n        #image=np.zeros((256,512,2))\n        from scipy.signal import convolve\n        \n        length=image.shape[1]\n        times=image.shape[0]\n        x=np.linspace(-1,1,length)\n        t=np.linspace(-1,1,times)\n        X, Y=np.meshgrid(t,x)\n        f2=lambda a,x0,s,b,x: a*np.exp(-(x-x0)**2/s**2)+b\n        bgnoise*=np.random.randn(length)\n\n        tempcorr=3*np.random.rand()\n        dAmp=dA#*np.random.rand()\n        shiftval=dX*np.random.randn()\n        dx=0\n        dx2=0\n        dAmp0=0\n        \n        bg0=f2(1,bigx0,biglam,0,x)\n        image.append({\"bg0\":bg0})\n        \n        \n        ll=(np.pi-.05)\n        for j in range(times):\n            #dx=np.sqrt(1-np.exp(-2/tempcorr))*dX*np.random.randn()+np.exp(-1/tempcorr)*dx\n            #dx2=np.sqrt(1-np.exp(-2/tempcorr))*dX*np.random.randn()+np.exp(-1/tempcorr)*dx2\n            dx=(.7*np.random.randn()+np.sin(ll*j))*dX\n            \n            bgnoiseC=f2(1,0,bgnoiseCval,dx,x)\n            #bgnoiseC2=f2(1,0,bgnoiseCval,dx2+shiftval,x)\n            bgnoiseC/=np.sum(bgnoiseC)\n            bg=f2(1,bigx0+dx,biglam,0,x)*(1+convolve(bgnoise,bgnoiseC,mode=\"same\"))\n            #bg2=f2(1,bigx0+dx2+shiftval,biglam,0,x)+convolve(bgnoise,bgnoiseC2,mode=\"same\")\n            #dAmp0=np.sqrt(1-np.exp(-2/tempcorr))*dAmp*np.random.randn()+np.exp(-1/tempcorr)*dAmp0\n            dAmp0=dA*np.random.randn()\n            bg*=(1+dAmp0)\n            image[j,:,0]=bg*(1+noise_lev*np.random.randn(length))+.4*noise_lev*np.random.randn(length)\n        \n        return image\n     \n\n    \nclass post_process(Feature):\n    \n    \n    def __init__(self, noise_lev=0, dX=0, dA=0, **kwargs):\n        super().__init__(\n            noise_lev=noise_lev, dX=dX, dA=dA, **kwargs\n        )\n\n    def get(self, image, **kwargs):\n        from scipy.signal import convolve2d\n        length=image.shape[1]\n        times=image.shape[0]\n        x=np.linspace(-1,1,length)\n        t=np.linspace(-1,1,times)\n        X, Y=np.meshgrid(t,x)\n        G= lambda a,b,x0,s,x: a*np.exp(-(x-x0)**2/s**2)+b\n        f2=lambda a,x0,s,b,x: a*np.exp(-(x-x0)**2/s**2)+b                         \n        \n        \n        bg0 = image.get_property(\"bg0\")\n        image[:,:,0]/=bg0 # Normalize image by the bare signal\n        \n        #image[:,:,0]/=np.mean(image[...,0],axis=0)        \n        image[:,:,0]-=np.expand_dims(np.mean(image[:,:,0],axis=0),axis=0) # Subtract mean over image\n\n        # Perform same preprocessing as done on experimental images\n        ono=np.ones((200,1))\n        ono[0:80]=1\n        ono[120:]=1\n        ono=ono/np.sum(ono)\n        image[:,:,0]-=convolve2d(image[:,:,0],ono,mode=\"same\")\n        image[:,:,0]-=convolve2d(image[:,:,0],np.transpose(ono),mode=\"same\")\n        \n        \n        \n        image[:,:,0]-=np.expand_dims(np.mean(image[:,:,0],axis=0),axis=0)\n        image[:,:,0]*=2000\n        \n        #image[:,:,0] /= np.max(np.max(image[:,:,0]))\n        \n        \n        #a=np.std(image[...,0],axis=0)\n        #print(a)\n        #image[:,:,0]/=a\n        #image.properties[\"I\"] /= 1000*np.mean(a)\n        #image.append({\"a\":a})\n        \n        \n        #image.properties[\"I\"] *= 1000\n#         I = image.get_property(\"I_initial\")\n#         print(I/np.mean(a)/1000)\n#         image.append({\"I\": I/np.mean(a)})\n        \n#        I = image.get_property(\"I_initial\")\n#         try:\n#             image.append({\"I\": I(a)})\n#             #print(I/np.mean(a))\n#         except:\n#             print('\"I\" not divided by a')\n        #image[...,2]/=a\n        #image=np.flip(image,axis=-1)\n        \n        \n        \n        return image\n\n    \nclass input_array(Feature):\n    __distributed__ = False\n    def get(self,image, **kwargs):\n        image=np.zeros((times,length,2))\n        return image\n\n        \ndef batch_function(image):\n    img = image[...,:1]\n    img = skimage.measure.block_reduce(img,(T_reduction_factor,L_reduction_factor,1),np.mean)\n    #GAN_output = unet.predict(np.expand_dims(img,axis=0))\n    #mask = skimage.measure.block_reduce(GAN_output, (1,64,16,1), np.mean)\n    #img = np.expand_dims(img,axis=0)\n    #print('GAN_output[0].shape',GAN_output[0].shape)\n    return img #GAN_output[0] #, mask\n\ndef label_function(image):\n    D = image.get_property(\"D\")\n    I = image.get_property(\"I_initial\")\n    #I *= 2000\n    #a = image.get_property(\"a\")\n    #I = image.get_property(\"I_initial\")\n    #I /= a*1000\n    #print(\"I:\",I)\n    \n    if np.sum(image[...,1]) < 2:\n        D = 0\n        I = 0\n    t_final = 8\n    L_final = 8\n    time_reduction = int(image.shape[0]/t_final)\n    len_reduction = int(image.shape[1]/L_final)\n    \n    #std_reduction = int(length/L_final)\n    #a = skimage.measure.block_reduce(a,(std_reduction,),np.mean)\n    mask = skimage.measure.block_reduce(image[...,1:2], (time_reduction,len_reduction,1), np.max)\n    #I = np.mean(mask/a)/1000\n    \n    #print('mask.shape',mask.shape)\n\n    labels = np.ones((t_final,L_final,2))\n    labels[...,0] *= I\n    labels[...,1:] = mask\n    #labels[...,-1] *= a\n    \n    return labels\n\nmae = tf.keras.losses.MeanAbsoluteError()\n\ndef diffusion_loss(T,P):\n    D_true = T[:,0,0,0] # Diffusion\n    D_pred = P\n    \n    return mae(D_true,D_pred) #+ mLoss\n\ndef zeroloss(T,P):\n    return tf.constant(0)\n\ndef mask_loss(ytrue,ypred):    \n    \n    #T = ytrue[...,-1]\n    #P = ypred[...,-1]\n    \n    T = ytrue[...,1]\n    P = ypred[...,-1]\n    #T=K.flatten(ytrue[...,1])\n    #P=K.flatten(ypred[...,-1])\n    \n    #T=K.flatten(ytrue)\n    #P=K.flatten(ypred)\n    loss1=-K.mean(T*K.log(P+1e-3)+(1-T)*K.log(1-P+1e-3))\n    #loss2=K.mean(T*K.abs(K.flatten(ytrue[...,0]-ypred[...,0])))+K.mean(T*K.abs(K.flatten(ytrue[...,1]-ypred[...,1])))\n    return loss1 #+ loss2\n\ndef generate_training_batch(net,image,batch_size):\n    \n    min_data_size = batch_size\n    max_data_size = batch_size+1\n\n    #convnet.load_weights('convnet.h5')\n    data_generator=dt.generators.ContinuousGenerator(image,\n                                                batch_function=batch_function,\n                                                label_function=label_function,\n                                                batch_size=batch_size,\n                                                min_data_size=min_data_size,\n                                                max_data_size=max_data_size)\n\n    with data_generator:\n        net.fit(data_generator, epochs=0, steps_per_epoch=1)\n        \n    b,L = data_generator[0] \n    return b,L\n\n\ndef plot_predictions(resnet,b,L):\n    x = np.linspace(0,1)\n    plt.plot(x,x)\n    \n    D_true = L[:,0,0,0]\n    D_pred = resnet.predict(b)[0]\n    #print(D_pred.shape)\n    #print(D_true.shape)\n    plt.scatter(D_true,D_pred) \n    \n    #print(resnet.predict(b)[1][...,-1].shape)\n    \n    masks = resnet.predict(b)[1][...,-1]\n    \n    \n    for img in range(0,2):\n        fig, ax = plt.subplots(1,2)\n        j = np.random.randint(batch_size)\n        cax = ax[0]\n        cax.imshow(L[...,1][j].T)\n\n        cax = ax[1]\n        cax.imshow(np.squeeze(masks[j]).T)\n        plt.show()\n\noptimizer = tf.keras.optimizers.Adam\n\n\n","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TRAIN"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"### Params to change below ###\nTRAIN = 1\nreset_resnet = 0\nload_resnet = 0\nGEN_NEW_VAL_DATA = 1 # Good thing to generate new val-data when changing parameters or when running for the first time          \nval_bsize = 16\nDEBUG = 0\n\n#resnet_to_load = '../input/network-weights/resnet_1024x512_low_contrast.h5'\n#resnet_to_load = './resnet_intensity_dec16.h5'\n#resnet_to_load = '../input/resnet-intensity-16-dec/resnet_intensity_dec16.h5'\nresnet_to_load = '../input/network-weights/resnet_intensity_dec-15.h5'\nresnet_to_load = '../input/intensities-11jan-nicelyseparatedh5/intensities_11-jan_nicely-separated.h5'\n\nfrom deeptrack.models import resnetcnn\nif reset_resnet:\n    resnet=resnetcnn(input_shape=(None, None, 1),\n            conv_layers_dimensions=(16, 32, 64, 128, 256), # sets downsampling size\n            upsample_layers_dimensions=(64, 128),\n            base_conv_layers_dimensions=(128, 128),\n            output_conv_layers_dimensions=(16, 16),\n            dropout=(),#0.01,\n            pooldim=2,\n            steps_per_pooling=1,\n            number_of_outputs=1,\n            output_activation=None,\n            loss=\"mae\",\n            layer_function=None,\n            BatchNormalization=False,\n            conv_step=None)\n\n\n# Choose loss functions when compiling\nresnet.compile(optimizer(lr=0.0001, amsgrad=True), loss=[diffusion_loss,mask_loss])\n    \n# Define image dimensions\nlength = 1024\nL_reduction_factor = 4\nreduced_length = int(length/L_reduction_factor)\n\ntimes = 256\nT_reduction_factor = 1\nreduced_times = int(times/T_reduction_factor)\n\nnbrParticles = lambda: np.clip(np.random.randint(5),0,1)\n\n### Defined with images\nInt = 0\nDs = 0 \nst = 0\n###\n\nimage=dt.FlipLR(dt.FlipUD(input_array() + get_diffusion_and_intensity() + #set_params(D=Ds, I=Int, s=st) + #get_diffusion(D=Ds) + get_intensity(I=Int,s=st) + \n                          gen_noise(dX=.00001+.00003*np.random.rand(),\n                                                  dA=0,\n                                                  noise_lev=.0001,\n                                                  #noise_lev = 0.0001*(0.75+0.75*np.random.rand()),\n                                                  biglam=0.6+.4*np.random.rand(),\n                                                  bgnoiseCval=0.03+.02*np.random.rand(),\n                                                  #bgnoiseCval=0.03+.05*np.random.rand(),\n                                                  #bgnoise=.08+.14*np.random.rand(),\n                                                  bgnoise=.08+.04*np.random.rand(),\n                                                  bigx0=lambda: .1*np.random.randn())\n                                      + get_trajectory(I=Int,s=st)**nbrParticles\n                                      + post_process()))\n\nbatch_size = 16\nmin_data_size = 16\nmax_data_size = 128\n\nif DEBUG:\n    batch_size = 1\n    min_data_size = 1\n    max_data_size = 2\n\ndata_generator = dt.generators.ContinuousGenerator(image,\n                                    batch_function=batch_function,\n                                    label_function=label_function,\n                                    batch_size=batch_size,\n                                    min_data_size=min_data_size,\n                                    max_data_size=max_data_size)                \nif GEN_NEW_VAL_DATA:\n    print('Generating validation data:')\n    b,L = generate_training_batch(resnet,image,batch_size=val_bsize)\n\n    \nif load_resnet:\n    resnet.load_weights(resnet_to_load)\n    \n# Combinations to use in phase plot\niOCs = np.array([1,2,5])*1e-4\n#iOCs = np.array([5])*1e-4\nplot_Ds = [1,1,1]\n#D_arr = np.array([10,20,50])\nD_arr = np.array([10,20,50])\n\nmake_phase_plot = 1\nphase_plot_freq = 5\nfull_phase_plot_freq = 20\n\nmake_val_plot = 1\nval_plot_freq = 5\n\nprint_outputs = 0\ninner_epochs = 10\nnumberLoops = 1000\n\nepochs = 0\ntotal_nr_epochs = 0\nprint('Generating training data:')\nif TRAIN:\n    with data_generator:\n        for epochs in range(numberLoops):\n            resnet.fit(data_generator, epochs=inner_epochs, steps_per_epoch=4)\n            epochs += inner_epochs\n            print('{} epochs performed.'.format(epochs))\n            \n            # Plot predictions of validation data\n            if make_val_plot and epochs % val_plot_freq == 0:\n                plot_predictions(resnet,b,L)\n\n                \n            # Make predictions on ALL test data\n            if make_phase_plot and epochs % phase_plot_freq == 0: \n                \n                if epochs % full_phase_plot_freq == 0:\n                    meas_indices = [0,10]\n                \n                else:\n                    R = np.random.randint(0,7)\n                    meas_indices = [R,R+2]\n                DX = length/2\n                unet = None\n                estimates = predict_on_testdata(resnet, unet, meas_indices, D_arr, iOCs, DX, print_outputs)\n                avg_estimates = calculate_estimates(estimates, iOCs, D_arr, print_outputs)\n                \n                print('D10')\n                print(avg_estimates['D10_iOC0.0002']['D'] - avg_estimates['D10_iOC0.0001']['D'])\n                print(avg_estimates['D10_iOC0.0005']['D'] - avg_estimates['D10_iOC0.0001']['D'])\n                print('D20')\n                print(avg_estimates['D20_iOC0.0002']['D'] - avg_estimates['D20_iOC0.0001']['D'])\n                print(avg_estimates['D20_iOC0.0005']['D'] - avg_estimates['D20_iOC0.0001']['D'])\n                print('D50')\n                print(avg_estimates['D50_iOC0.0002']['D'] - avg_estimates['D50_iOC0.0001']['D'])\n                print(avg_estimates['D50_iOC0.0005']['D'] - avg_estimates['D50_iOC0.0001']['D'])\n\n                \n                I_scaling_factor = 1\n                \n                plot_test_predictions(avg_estimates,plot_Ds, I_scaling_factor)   \n                \n                            \n\n#             # Plot predictions of one randomly selected test measurement\n#             if make_test_plots and epochs % 5 == 0 and not (epochs % 20 == 0):\n#                 R = np.random.randint(9)\n#                 meas_indices = [R,R+1]\n#                 DX = length/2\n#                 estimates = predict_on_testdata(resnet, unet, meas_indices, D_arr, iOCs, DX, print_outputs)\n#                 avg_estimates = calculate_estimates(estimates, iOCs, D_arr, print_outputs)\n\n#                 plot_test_predictions(avg_estimates)   \n\n#    return b,L\n#b,L = generate_training_batch(image,1)\n\n# plt.figure(figsize=(10,2))\n# plt.imshow(im[...,0].T,aspect='auto')\n# plt.colorbar()\n    \n# plt.figure(figsize=(10,2))\n# plt.imshow(im[...,1].T,aspect='auto')\n# plt.colorbar()\n\n# print(im.get_property(\"D\"))\n# print(im.get_property(\"I\"))\n\nresolve_image = 0\nif resolve_image:\n    im=image.update().resolve()\n    DX = length/2\n    im=image.update().resolve()\n    print('D: {:.2f}'.format(im.get_property(\"D\")**2*57/(256**2)*DX**2))\n    print('I: {:.2f}e-4'.format(im.get_property(\"I\")*10))\n    print('s: {:.2f}'.format(im.get_property(\"s\")))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet.save('intensities_11-jan_nicely-separated.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/test-data-no-bgstd-7-jan/24-08-20_16-06-15_D10_iOC0.0001_M.mat.npy'\nA = np.load(path)\nA = A[256:512]\nplt.plot(np.std(A,axis=0))\nplt.figure()\nplt.imshow(np.squeeze(A).T,aspect='auto')\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tot_img = np.zeros_like(b[0,...,0])\nN = 16\nfor j in range(0,N):\n    tot_img += b[j,...,0]\ntot_img /= N\nplt.imshow(tot_img)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j = 22\nplt.plot(np.std(b[j,...,0],axis=0))\nplt.figure()\nimg = b[j,...]\nimg /= np.max(np.max(img))\nplt.imshow(np.squeeze(img).T,aspect='auto')\nplt.colorbar()\nprint(L[j,0,0,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in range(10):\n    plt.figure(figsize=(8,2))\n    plt.imshow(b[j,...,0].T,aspect='auto')\n    I = L[j,0,0,0]\n    plt.title('I:{:.2f}'.format(I))\n    plt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet.save('resnet_intensity_jan7.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L[0,:,:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L[0,0,0,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j = 1\nim = b[...,j]\n\nplt.figure(figsize=(10,2))\nplt.imshow(im[...,0].T,aspect='auto')\nplt.colorbar()\n    \nplt.figure(figsize=(10,2))\nplt.imshow(im[...,1].T,aspect='auto')\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j = 2\nI = L[j,0,0,0]\nprint(I/1000)\nprint(I)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet.save('resnet_intensity_dec-15.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict on all measurements"},{"metadata":{"trusted":true},"cell_type":"code","source":"meas_indices = [0,10]\nprint_outputs = 0\nDX = length/2\nestimates = predict_on_testdata(resnet, unet, meas_indices, D_arr, iOCs, DX, print_outputs)\navg_estimates = calculate_estimates(estimates, iOCs, D_arr, print_outputs)\n\nplot_Ds = [1,1,1]\nplot_test_predictions(avg_estimates,plot_Ds) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loop over images to make predictions (not used right now)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Dtot = 0\nfile = '../input/testdata-1-dec/24-08-20_16-06-15_D50_iOC0.0005_M.mat.npy'\nfile = '../input/testdata-1-dec/24-08-20_17-17-45_D0_iOC0.0001_M.mat.npy'\nBsm_full = np.load(file)\nL = Bsm_full.shape[0]\nN = int(L/128)\nfor j in range(0,int(N/3)):\n    Bsm = np.copy(Bsm_full[j*128:j*128+128,:128])\n    Bsm = np.flip(Bsm,axis = 0)\n    img = np.reshape(Bsm,(1,128,128,1))\n    segmentation = unet.predict(img)\n    pred = resnet.predict(segmentation)\n    DP = pred[0][0][0]\n    DPreal = (DP**2*57*2)\n    Dtot+=DPreal\n    #print(DPreal)\nprint('Avg:',Dtot/N)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}